# HYCO: Hybrid Consistency Models for Parameter Estimation in PDEs

A comprehensive framework for learning physical parameters and solutions of partial differential equations (PDEs) using hybrid physics-neural network models. This repository implements both **static** (steady-state) and **dynamic** (time-dependent) PDE solvers with various training strategies including Physics-Informed Neural Networks (PINNs), Finite Element Method (FEM), and novel hybrid consistency approaches.

## ğŸ”¬ Overview

HYCO (Hybrid Consistency) combines physics-based models with neural networks to solve inverse problems in PDEs. The key innovation is the **hybrid consistency loss** that enforces agreement between physics-based and data-driven components, enabling robust parameter estimation even with sparse or noisy data.

### Key Features

- **Multiple PDE Systems**: Darcy flow, Helmholtz equation, heat equation, Gray-Scott reaction-diffusion
- **Hybrid Training Strategies**: Seamlessly blend physics constraints with data-driven learning
- **Parameter Learning**: Automatically infer unknown physical parameters (diffusion coefficients, reaction rates, etc.)
- **Flexible Architectures**: JAX/Flax for static problems, PyTorch for dynamic systems
- **Comprehensive Benchmarking**: Compare PINN, FEM, and hybrid approaches

## ğŸ“ Repository Structure

```
HYCO-Code/
â”œâ”€â”€ StaticHYCO/              # Static (steady-state) PDE problems
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ darcy.py         # Darcy flow inverse problem
â”‚       â”œâ”€â”€ helmholtz.py     # Helmholtz equation with Gaussian coefficients
â”‚       â”œâ”€â”€ models/          # Model architectures
â”‚       â”‚   â”œâ”€â”€ physical_model.py    # FEM-based physics solver
â”‚       â”‚   â”œâ”€â”€ synthetic_model.py   # Neural network architectures
â”‚       â”‚   â””â”€â”€ other_models.py      # PINN implementations
â”‚       â”œâ”€â”€ tools/           # Utilities
â”‚       â”‚   â”œâ”€â”€ training.py          # Training loops (Hybrid, FEM, PINN)
â”‚       â”‚   â”œâ”€â”€ finite_element_method.py  # FEM solver
â”‚       â”‚   â”œâ”€â”€ plotting.py          # Visualization tools
â”‚       â”‚   â””â”€â”€ experiment_utils.py  # Helper functions
â”‚       â”œâ”€â”€ files/           # Saved results and intermediate data
â”‚       â”œâ”€â”€ results/         # Generated plots and figures
â”‚       â””â”€â”€ cache/           # Cached solutions for reproducibility
â”‚
â”œâ”€â”€ DynamicHYCO/             # Dynamic (time-dependent) PDE problems
â”‚   â”œâ”€â”€ GrayScott/           # Gray-Scott reaction-diffusion system
â”‚   â”‚   â”œâ”€â”€ MAIN.py          # Main training script for hybrid models
â”‚   â”‚   â”œâ”€â”€ PINN.py          # PINN with learnable diffusion coefficients
â”‚   â”‚   â”œâ”€â”€ PLOT.py          # Visualization script
â”‚   â”‚   â”œâ”€â”€ shared/          # Shared modules
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py             # Gray-Scott physics model
â”‚   â”‚   â”‚   â”œâ”€â”€ pinn.py              # PINN architecture and trainer
â”‚   â”‚   â”‚   â”œâ”€â”€ training.py          # Hybrid training loop
â”‚   â”‚   â”‚   â”œâ”€â”€ data_generator.py    # Synthetic data generation
â”‚   â”‚   â”‚   â””â”€â”€ visualization.py     # Plotting utilities
â”‚   â”‚   â”œâ”€â”€ data/            # Training data
â”‚   â”‚   â””â”€â”€ results/         # Trained models and metrics
â”‚   â”‚
â”‚   â””â”€â”€ Heat/                # Heat equation parameter estimation
â”‚       â”œâ”€â”€ MAIN.py          # Main training script
â”‚       â”œâ”€â”€ PINN.py          # PINN implementation for heat equation
â”‚       â”œâ”€â”€ PLOT_COEFFICIENTS.py  # Plot learned coefficients
â”‚       â”œâ”€â”€ PLOT_ERRORS.py        # Error analysis
â”‚       â”œâ”€â”€ models/          # Model implementations
â”‚       â”‚   â”œâ”€â”€ FEM.py              # FEM solver for heat equation
â”‚       â”‚   â”œâ”€â”€ NN.py               # Neural network architectures
â”‚       â”‚   â”œâ”€â”€ training.py         # Training utilities
â”‚       â”‚   â””â”€â”€ generate_data.py    # Data generation
â”‚       â”œâ”€â”€ data/            # Training datasets
â”‚       â””â”€â”€ parameters/      # Learned parameters and errors
â”‚
â””â”€â”€ .gitignore               # Git ignore file
```

## ğŸš€ Getting Started

### Prerequisites

The project uses different frameworks for static and dynamic problems:

**For StaticHYCO (JAX-based):**
```bash
pip install jax jaxlib flax optax numpy scipy matplotlib
```

**For DynamicHYCO (PyTorch-based):**
```bash
pip install torch numpy scipy matplotlib pandas
```

**Optional (for GPU acceleration):**
- JAX: Follow [JAX GPU installation guide](https://github.com/google/jax#installation)
- PyTorch: Install CUDA-enabled PyTorch from [pytorch.org](https://pytorch.org/)

### Quick Start

#### 1. Static Problems (Darcy Flow / Helmholtz)

Run the Darcy flow inverse problem with different noise levels:

```bash
cd StaticHYCO/src
python darcy.py
```

Run the Helmholtz equation experiment:

```bash
cd StaticHYCO/src
python helmholtz.py
```

**Key Parameters to Modify:**
- `noise_level`: Amount of observation noise (0.0, 0.05, 0.1, etc.)
- `config.epochs`: Number of training epochs
- `config.n_train`: Number of training observations
- `config.subdomain`: Region where observations are available

#### 2. Dynamic Problems (Gray-Scott)

Train hybrid models with different consistency weights:

```bash
cd DynamicHYCO/GrayScott
python MAIN.py
```

Train PINN with learnable diffusion coefficients:

```bash
cd DynamicHYCO/GrayScott
python PINN.py
```

Visualize results:

```bash
python PLOT.py
```

#### 3. Heat Equation Parameter Estimation

Train on different data fractions (full, half, quarter):

```bash
cd DynamicHYCO/Heat
python MAIN.py
```

## ğŸ§ª Experiments

### StaticHYCO: Steady-State Inverse Problems

**Darcy Flow Problem:**
- **PDE**: `-âˆ‡Â·(Îº(x,y)âˆ‡u) + Î·(x,y)u = f(x,y)`
- **Goal**: Learn spatially-varying diffusion `Îº` and reaction `Î·` coefficients
- **Parameters**: 10 coefficients controlling Fourier series expansion
- **Methods**: Hybrid (physics + neural), FEM (physics-only), PINN (neural + physics loss)

**Helmholtz Equation:**
- **PDE**: `-âˆ‡Â·(Îº(x,y)âˆ‡u) + Î·(x,y)u = f(x,y)`
- **Coefficients**: Gaussian-shaped `Îº(x,y)` and `Î·(x,y)` 
- **Parameters**: 6 parameters (amplitude, centers for each coefficient)
- **Special Feature**: Subdomain observations (only 25% of domain observed)

### DynamicHYCO: Time-Dependent Systems

**Gray-Scott Reaction-Diffusion:**
- **PDEs**: 
  - `âˆ‚u/âˆ‚t = Duâˆ‡Â²u - uvÂ² + f(1-u)`
  - `âˆ‚v/âˆ‚t = Dvâˆ‡Â²v + uvÂ² - (f+k)v`
- **Goal**: Learn diffusion coefficients `Du` and `Dv`
- **Features**: 
  - Pattern formation dynamics
  - Consistency-weighted hybrid training
  - Comparison of pure data-driven vs. physics-constrained models

**Heat Equation:**
- **PDE**: `âˆ‚u/âˆ‚t = âˆ‡Â·(Îº(x,y)âˆ‡u)`
- **Goal**: Learn spatially-varying thermal conductivity `Îº(x,y)`
- **Experiments**: Training with full, half, and quarter datasets

## ğŸ“Š Results and Outputs

### Generated Files

- **`results/`**: Training metrics, loss curves, parameter evolution
- **`figures/`**: Comparison plots, solution visualizations, error heatmaps
- **`data/`**: Generated training data, cached solutions
- **`models/` or `parameters/`**: Saved model weights and learned parameters

### Typical Outputs

1. **Solution Comparisons**: Ground truth vs. learned solutions
2. **Parameter Evolution**: How learned parameters converge during training
3. **Error Analysis**: L2 errors, pointwise errors, parameter errors
4. **Consistency Plots**: Agreement between physics and neural components

## ğŸ”§ Configuration

### StaticHYCO Configuration

Edit configuration classes in `darcy.py` or `helmholtz.py`:

```python
class Config:
    epochs = 2500              # Training epochs
    n_train = 50              # Number of training points
    syn_lr = 5e-3             # Neural network learning rate
    phys_lr = 5e-3            # Physics model learning rate
    hidden_dims = (256, 256)  # Neural network architecture
    noise_level = 0.0         # Observation noise level
```

### DynamicHYCO Configuration

Edit training parameters in scripts or `shared/config.py`:

```python
training_params = {
    'pre_epochs': 200,         # Pre-training epochs
    'epochs': 200,             # Main training epochs
    'post_epochs': 200,        # Fine-tuning epochs
    'batch_size': 1000,
    'physical_lr': 0.008,      # Physics parameters learning rate
    'neural_lr': 0.001,        # Neural network learning rate
    'physical_consistency_weight': 1.0,  # Consistency loss weight
}
```

## ğŸ“– Key Concepts

### Hybrid Consistency Training

The hybrid model combines:
1. **Physics Model**: FEM or differential equation solver with learnable parameters
2. **Neural Model**: Flexible neural network for residual/correction
3. **Consistency Loss**: Enforces agreement between physics and neural predictions

**Loss Function:**
```
L = Î»_data * L_data + Î»_physics * L_physics + Î»_consistency * L_consistency
```

Where:
- `L_data`: Fit to observations
- `L_physics`: Satisfy PDE constraints (for PINN)
- `L_consistency`: Agreement between physics and neural models

### Training Strategies

1. **FEM-Only**: Pure physics-based optimization (no neural network)
2. **PINN**: Neural network with physics-informed loss
3. **Hybrid**: Combined physics + neural with consistency enforcement

### Advantages of Hybrid Approach

- **Robustness**: Better generalization with limited data
- **Interpretability**: Learned physical parameters have clear meaning
- **Efficiency**: Physics constraints guide neural network training
- **Flexibility**: Can handle model misspecification via neural correction

## ğŸ“š Publications

This code implements methods from research on hybrid physics-neural models for inverse problems. Key concepts include:

- Physics-informed machine learning
- Parameter estimation in PDEs
- Hybrid modeling strategies
- Finite element methods with neural networks

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Additional PDE systems
- New neural architectures
- Optimization strategies
- Documentation and examples

## ğŸ“ License

[Add your license information here]

## ğŸ™ Acknowledgments

This project uses:
- [JAX](https://github.com/google/jax) - High-performance numerical computing
- [Flax](https://github.com/google/flax) - Neural network library for JAX
- [PyTorch](https://pytorch.org/) - Deep learning framework
- Finite element methods for physics-based solvers

## ğŸ“§ Contact

[Add your contact information here]

---

**Note**: This is research code. While we strive for correctness and reproducibility, some experimental features may require tuning for your specific use case.
